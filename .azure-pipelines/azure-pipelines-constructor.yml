# Run constructor after phenix-feedstock finishes

# no continuous integration builds or pull requests
trigger: none
pr: none

resources:
  pipelines:
  - pipeline: phenix_feedstock
    project: 'feedstock-builds'
    source: 'phenix-feedstock'
    branch: 'main'
    trigger:
      branches:
        include:
          - main
  - pipeline: data_cache
    source: 'Update data cache'

stages:
# =============================================================================
- stage: linux_macOS

  jobs:
  - job: Construct_phenix_installer

    strategy:
      maxParallel: 6
      matrix:
        linux_py39:
          vmImage: ubuntu-latest
          artifact_platform: linux_64
          platform: linux-64
          cuda: 0
          conda: Linux
          py_ver: 3.9
          np_ver: 1.22
        cuda12_linux_py39:
          vmImage: ubuntu-latest
          artifact_platform: linux_64
          platform: linux-64
          cuda: 12
          conda: Linux
          py_ver: 3.9
          np_ver: 1.22
        linux_py310:
          vmImage: ubuntu-latest
          artifact_platform: linux_64
          platform: linux-64
          cuda: 0
          conda: Linux
          py_ver: 3.10
          np_ver: 1.22
        linux_py311:
          vmImage: ubuntu-latest
          artifact_platform: linux_64
          platform: linux-64
          cuda: 0
          conda: Linux
          py_ver: 3.11
          np_ver: 1.23
        linux_py312:
          vmImage: ubuntu-latest
          artifact_platform: linux_64
          platform: linux-64
          cuda: 0
          conda: Linux
          py_ver: 3.12
          np_ver: 1.26
        macOS_py39:
          vmImage: macOS-latest
          artifact_platform: osx_64
          platform: osx-64
          cuda: 0
          conda: MacOSX
          py_ver: 3.9
          np_ver: 1.22
        macOS_py310:
          vmImage: macOS-latest
          artifact_platform: osx_64
          platform: osx-64
          cuda: 0
          conda: MacOSX
          py_ver: 3.10
          np_ver: 1.22
        macOS_py311:
          vmImage: macOS-latest
          artifact_platform: osx_64
          platform: osx-64
          cuda: 0
          conda: MacOSX
          py_ver: 3.11
          np_ver: 1.23
        macOS_py312:
          vmImage: macOS-latest
          artifact_platform: osx_64
          platform: osx-64
          cuda: 0
          conda: MacOSX
          py_ver: 3.12
          np_ver: 1.26
        macOS_arm64_py39:
          vmImage: macOS-latest
          artifact_platform: osx_arm64
          platform: osx-arm64
          cuda: 0
          conda: MacOSX
          py_ver: 3.9
          np_ver: 1.22
        macOS_arm64_py310:
          vmImage: macOS-latest
          artifact_platform: osx_arm64
          platform: osx-arm64
          cuda: 0
          conda: MacOSX
          py_ver: 3.10
          np_ver: 1.22
        macOS_arm64_py311:
          vmImage: macOS-latest
          artifact_platform: osx_arm64
          platform: osx-arm64
          cuda: 0
          conda: MacOSX
          py_ver: 3.11
          np_ver: 1.23
        macOS_arm64_py312:
          vmImage: macOS-latest
          artifact_platform: osx_arm64
          platform: osx-arm64
          cuda: 0
          conda: MacOSX
          py_ver: 3.12
          np_ver: 1.26

    pool:
      vmImage: $(vmImage)
    timeoutInMinutes: 360

    # variable for version
    variables:
      version: 1234

    steps:

    - task: InstallSSHKey@0
      inputs:
        knownHostsEntry: boa.lbl.gov ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAnPOtqyYASs6hc3fsmUQn92ovSozJsMsJyrMWjppUERX1tD4Fh0D7YaNhLvYpKi5mYVREo+tsKoOatCcqKGHCONWpzx7JHXUzfIBsy6nCeygRyyW4yuyoCuYFvOYLkaM4PrN/7XaZEnp1ux6/ZcbRxBDNK4f42svJUV39OX33tRuQWpP+O85paJr1ePHVz6U2n14a+3fRN3DBMti1dJuKOThU4djYEBQimx54pnW71eYORN2oUz+N/4RHAcomtxZpcUMl3Qadw8hD4s1XM6fzJ0Que7KefnnrPOgAEtZxKl9j09aaE70Oh+ie5Y6ckwddJ/4qZB5m2tBaEi3xuy0TSQ==
        sshPublicKey: ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA7XgVgdU9GmZuo5yVyW/htrAuxe7ypuq7IowWwfUC0WZw9SPzQ8kOGj63plF3ytx/qpgvUlS1AiywO20rZ83gHmRdAiuvt9laH09KlWEUhIhAQTzesqBG5aUT0MKo01yxijoRl5HC8w/MdOanc0h01e6IxnZvgG0N30RB1i4xVPCtR/VBmXSp4R0T+Q/gJjfQssuBxHVMrrute4V3uUHek58FL2QgUB0+zq6ipETjuCJxTSyYVAFtCYDPYs+0lAYYkWrXALCr9kX9s22jYtkyv5kNw6mEW8nhtA7GbTdJLv4M6/WYtcvQV8TDcNCfltOfl81U3gcZ9zhQDKGVoNaJEw== buildbot@cci.lbl.gov
        sshKeySecureFile: id_rsa
      displayName: Download SSH key

    - task: DownloadSecureFile@1
      name: upload_key
      inputs:
        secureFile: phenix-lbl-04e6cb0d1bf7.json
      displayName: Download Google Drive credentials

    # download sources
    - checkout: self

    # clean up linux image
    - script: |
        sudo $(Build.Repository.LocalPath)/scripts/clean_linux.sh
      displayName: Clean up linux image
      condition: eq(variables['platform'], 'linux-64')

    - script: |
        sudo swapoff /swapfile
        sudo rm -fr /swapfile
        df -h
        free -h

        cat /proc/swaps
        sudo cat /etc/fstab
      displayName: Remove swap
      condition: eq(variables['platform'], 'linux-64')
      continueOnError: true

    - script: |
        for p in docker-ce docker-ce-cli containerd.io \
          gfortran-12 gfortran-13 gfortran 14 \
          g++-12 g++-13 g++-14 \
          clang-16 clang-17 clang-18 \
          php rubygems selenium node dotnet-sdk-8.0 postgresql mysql; do
          echo "Removing ${p}"
          echo "======================="
          sudo apt-get purge -y ${p}
        done
        sudo apt-get autoremove -y
        sudo apt-get clean -y

        sudo rm -fr ${CONDA}
        sudo rm -fr ${VCPKG_INSTALLATION_ROOT}
      displayName: Clean up linux image some more
      condition: eq(variables['platform'], 'linux-64')
      continueOnError: true

    - script: |
        set -xe

        pwd
        ls

        cd $(Pipeline.Workspace)
        pwd
        ls
      displayName: Debug information

    # install miniforge
    - task: DownloadPipelineArtifact@2
      inputs:
        source: 'specific'
        project: '$(resources.pipeline.data_cache.projectID)'
        pipeline: '$(resources.pipeline.data_cache.pipelineID)'
        artifact: 'miniforge'
        path: $(Pipeline.Workspace)/miniforge
      displayName: Download miniforge

    - script: |
        set -xe
        bash $(Pipeline.Workspace)/miniforge/Miniforge3-$(conda)-x86_64.sh -b -u -p $(Pipeline.Workspace)/miniforge
      displayName: Install miniforge

    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh
        conda update --all -y -n base
        conda install -n base -c conda-forge -y conda-build constructor jinja2
      displayName: Update miniforge

    # set up Google Drive upload environment
    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh
        if [ -d $(Pipeline.Workspace)/miniforge/envs/upload ]; then
          conda remove -n upload -y --all
        fi
        conda create -n upload -y python=3.10
        conda activate upload
        pip install --no-input google-api-python-client google-auth-httplib2 google-auth-oauthlib oauth2client
      displayName: Set up upload environment
      retryCountOnTaskFailure: 3

    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh

        rm -fr $(Pipeline.Workspace)/conda*

        conda activate base

        conda clean -y --all

        constructor --clean

        df -h

      displayName: Clean up

    # download latest phenix conda package
    - task: DownloadPipelineArtifact@2
      inputs:
        source: 'specific'
        project: '$(resources.pipeline.phenix_feedstock.projectID)'
        pipeline: '$(resources.pipeline.phenix_feedstock.pipelineID)'
        preferTriggeringPipeline: true
        allowPartiallySucceededBuilds: true
        allowFailedBuilds: false
        buildVersionToDownload: 'latestFromBranch'
        branchName: 'refs/heads/main'
        # patterns: '**/*$(artifact_platform)_python$(py_ver)*'
        # patterns: '**/*artifacts*$(artifact_platform)_numpy$(np_ver)python$(py_ver)*'
        patterns: '**/*artifacts*$(artifact_platform)_python$(py_ver)*'
      displayName: Download Phenix package

    # download latest chem_data package
    - task: DownloadPipelineArtifact@2
      inputs:
        source: 'specific'
        project: '$(resources.pipeline.phenix_feedstock.projectID)'
        pipeline: '$(resources.pipeline.phenix_feedstock.pipelineID)'
        preferTriggeringPipeline: false
        allowPartiallySucceededBuilds: true
        allowFailedBuilds: false
        buildVersionToDownload: 'latestFromBranch'
        branchName: 'refs/heads/chem_data'
        patterns: '**/*artifacts*linux*'
      displayName: Download chem_data package

    - script: |
        set -xe

        mkdir $(Pipeline.Workspace)/$(platform)
        mkdir $(Pipeline.Workspace)/noarch

        cd $(Pipeline.Workspace)
        ls

        for d in conda_artifacts*/; do
          cd $(Pipeline.Workspace)/${d}
          unzip phenix-feedstock*.zip

          if [ -d build_artifacts/$(platform) ]; then
            cd build_artifacts/$(platform)
          elif [ -d $(platform) ]; then
            cd $(platform)
          fi
          for f in `/bin/ls phenix*.conda 2> /dev/null`; do
            mv ${f} $(Pipeline.Workspace)/$(platform)/
          done

          if [ -d $(Pipeline.Workspace)/${d}/build_artifacts/noarch ]; then
            cd $(Pipeline.Workspace)/${d}/build_artifacts/noarch
            for f in `/bin/ls chem_data*.conda 2> /dev/null`; do
              mv ${f} $(Pipeline.Workspace)/noarch/
            done
          fi
        done

        rm -fr $(Pipeline.Workspace)/conda_artifacts*

        ls $(Pipeline.Workspace)/$(platform)/
        ls $(Pipeline.Workspace)/noarch/
      displayName: Extract artifact

    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh
        cd $(Pipeline.Workspace)
        conda index .
        ls
      displayName: Index file channel

    - script: |
        set -xe
        cd constructor
        version=`python3 update_version.py --version $(Pipeline.Workspace)/$(platform)/phenix*`
        echo "##vso[task.setVariable variable=version]$version"
        echo $(version)
      displayName: Set and update version

    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh

        conda activate upload

        cd $(Pipeline.Workspace)/$(platform)
        for f in `/bin/ls $(Pipeline.Workspace)/$(platform)/*.conda`; do
          echo Uploading ${f}
          python $(Build.Repository.LocalPath)/scripts/google_drive.py \
            --credentials $(upload_key.secureFilePath) \
            --drive "Phenix Installers" \
            --folder "$(version)" \
            --subfolder "$(platform)" \
            --file ${f}
          sleep 60
        done
      displayName: Upload platform conda package to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true

    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh

        conda activate upload

        cd $(Pipeline.Workspace)/noarch
        for f in `/bin/ls $(Pipeline.Workspace)/noarch/*.conda`; do
          echo Uploading ${f}
          python $(Build.Repository.LocalPath)/scripts/google_drive.py \
            --credentials $(upload_key.secureFilePath) \
            --drive "Phenix Installers" \
            --folder "$(version)" \
            --subfolder "noarch" \
            --file ${f}
          sleep 60
        done
      displayName: Upload noarch conda package to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true
      condition: and(eq(variables['py_ver'], '3.9'), eq(variables['platform'], 'linux-64'), eq(variables['cuda'], 0))

    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh

        if [ -d $(Pipeline.Workspace)/miniforge/envs/phenix ]; then
          conda remove -n phenix -y --all
        fi

        CONDA_SUBDIR=$(platform) conda create -n phenix -y -c conda-forge python=$(py_ver)
        conda activate phenix

        cd $(Pipeline.Workspace)/$(platform)
        for f in `/bin/ls phenix*.conda`; do
          CONDA_SUBDIR=$(platform) conda install -y -c local ${f}
        done

        cd ${CONDA_PREFIX}/share/phenix/conda_envs

        pyver=`echo $(py_ver) | sed 's/\.//'`

        env_file=phenix_py${pyver}_$(platform).txt2
        if [ $(cuda) -gt "0" ]; then
          env_file=phenix_py${pyver}_cuda$(cuda)_$(platform).txt
        fi
        conda install -y --file ${env_file}

        cd $(Pipeline.Workspace)/noarch
        CONDA_SUBDIR=$(platform) conda install -y chem_data*.conda

        conda clean -y --all

      displayName: Create installer environment
      retryCountOnTaskFailure: 3

    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh

        conda activate phenix

        cp ${CONDA_PREFIX}/share/phenix/CHANGES ./constructor/gui/readme_macos.txt
      displayName: Update Changelog

    - script: |
        set -xe

        df -h
      displayName: Check disk space

    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh
        conda activate base
        # cross-platform constructor
        if [[ "$(platform)" == *"arm64" ]]; then
          TEMP_DIR=$(mktemp -d)
          CONDA_SUBDIR=$(platform) conda create -p ${TEMP_DIR} -y conda-standalone
          CONDA_STANDALONE=${TEMP_DIR}/standalone_conda/conda.exe
        fi

        cd constructor

        if [[ "$(platform)" == *"arm64" ]]; then
          export CONDA_EXE=${CONDA_STANDALONE}
          constructor . --conda-exe ${CONDA_STANDALONE} --platform osx-arm64
        else
          constructor .
        fi

        ls
        df -h
      displayName: Create installer
      retryCountOnTaskFailure: 3

    - script: |
        set -xe
        cd ./constructor
        ls
        mv Phenix-$(version)-Linux-x86_64.sh Phenix-$(version)-CUDA$(cuda)-Linux-x86_64.sh
        ls
      displayName: Rename CUDA installer
      condition: gt(variables['cuda'], 0)
      continueOnError: true

    - script: |
        set -xe
        source $(Pipeline.Workspace)/miniforge/etc/profile.d/conda.sh

        conda activate upload

        cd ./constructor
        for f in `/bin/ls Phenix*`; do
          echo Uploading ${f}
          python $(Build.Repository.LocalPath)/scripts/google_drive.py \
            --credentials $(upload_key.secureFilePath) \
            --drive "Phenix Installers" \
            --folder "$(version)" \
            --subfolder "$(py_ver)" \
            --file ${f}
          sleep 60
        done

      displayName: Upload installer to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true

    - task: CopyFilesOverSSH@0
      inputs:
        sshEndpoint: cci3
        sourceFolder: $(Build.Repository.LocalPath)/constructor
        contents: Phenix*
        targetFolder: /net/cci-filer2/raid1/auto_build/phenix_installers/$(version)
        overwrite: false
      displayName: Upload installer to Berkeley
      condition: and(eq(variables['py_ver'], '3.9'), succeeded())
      continueOnError: true

# =============================================================================
- stage: win
  dependsOn: []

  jobs:
  - job: Construct_phenix_win_installer

    strategy:
      matrix:
        win_py39:
          vmImage: windows-latest
          artifact_platform: win_64
          platform: win-64
          py_ver: 3.9
          pyver: 39
          np_ver: 1.22
        win_py310:
          vmImage: windows-latest
          artifact_platform: win_64
          platform: win-64
          py_ver: 3.10
          pyver: 310
          np_ver: 1.22
        win_py311:
          vmImage: windows-latest
          artifact_platform: win_64
          platform: win-64
          py_ver: 3.11
          pyver: 311
          np_ver: 1.23
        win_py312:
          vmImage: windows-latest
          artifact_platform: win_64
          platform: win-64
          py_ver: 3.12
          pyver: 312
          np_ver: 1.26

    pool:
      vmImage: $(vmImage)
    timeoutInMinutes: 360

    # variable for version
    variables:
      version: 1234

    steps:

    - task: InstallSSHKey@0
      inputs:
        knownHostsEntry: boa.lbl.gov ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAnPOtqyYASs6hc3fsmUQn92ovSozJsMsJyrMWjppUERX1tD4Fh0D7YaNhLvYpKi5mYVREo+tsKoOatCcqKGHCONWpzx7JHXUzfIBsy6nCeygRyyW4yuyoCuYFvOYLkaM4PrN/7XaZEnp1ux6/ZcbRxBDNK4f42svJUV39OX33tRuQWpP+O85paJr1ePHVz6U2n14a+3fRN3DBMti1dJuKOThU4djYEBQimx54pnW71eYORN2oUz+N/4RHAcomtxZpcUMl3Qadw8hD4s1XM6fzJ0Que7KefnnrPOgAEtZxKl9j09aaE70Oh+ie5Y6ckwddJ/4qZB5m2tBaEi3xuy0TSQ==
        sshPublicKey: ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA7XgVgdU9GmZuo5yVyW/htrAuxe7ypuq7IowWwfUC0WZw9SPzQ8kOGj63plF3ytx/qpgvUlS1AiywO20rZ83gHmRdAiuvt9laH09KlWEUhIhAQTzesqBG5aUT0MKo01yxijoRl5HC8w/MdOanc0h01e6IxnZvgG0N30RB1i4xVPCtR/VBmXSp4R0T+Q/gJjfQssuBxHVMrrute4V3uUHek58FL2QgUB0+zq6ipETjuCJxTSyYVAFtCYDPYs+0lAYYkWrXALCr9kX9s22jYtkyv5kNw6mEW8nhtA7GbTdJLv4M6/WYtcvQV8TDcNCfltOfl81U3gcZ9zhQDKGVoNaJEw== buildbot@cci.lbl.gov
        sshKeySecureFile: id_rsa
      displayName: Download SSH key

    - task: DownloadSecureFile@1
      name: upload_key
      inputs:
        secureFile: phenix-lbl-04e6cb0d1bf7.json
      displayName: Download Google Drive credentials

    - task: DownloadSecureFile@1
      name: nsis_zip
      inputs:
        secureFile: nsis-binary-7336-1.zip
      displayName: Download nsisbi

    # download sources
    - checkout: self

    # add conda to path
    # https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/anaconda?view=azure-devops&tabs=windows#add-conda-to-your-system-path
    - powershell: Write-Host "##vso[task.prependpath]$env:CONDA\Scripts"
      displayName: Add conda to PATH

    # install conda build
    - script: |
        conda install -n base -y conda-index
        conda update -n base -y --all
        conda create -n construct -c conda-forge -y conda-build python=3.10 constructor jinja2
        conda clean -y --all
        conda info
        call activate construct
        call conda info
      displayName: Install conda-build and constructor
      retryCountOnTaskFailure: 3

    # replace nsis with nsisbi
    - script: |
        unzip $(nsis_zip.secureFilePath)
        xcopy /S /Y /F nsis-binary-7336-1\* C:\Miniconda\envs\construct\NSIS
        dir nsis-binary-7336-1
        dir C:\Miniconda\envs\construct\NSIS
      displayName: Replace NSIS in constructor environment

    # set up Google Drive upload environment
    - script: |
        conda remove -n upload -y --all
        conda create -n upload -y python=3.10
        call activate upload
        pip install --no-input google-api-python-client google-auth-httplib2 google-auth-oauthlib oauth2client
      displayName: Set up upload environment
      retryCountOnTaskFailure: 3

    # download latest phenix conda package
    - task: DownloadPipelineArtifact@2
      inputs:
        source: 'specific'
        project: '$(resources.pipeline.phenix_feedstock.projectID)'
        pipeline: '$(resources.pipeline.phenix_feedstock.pipelineID)'
        preferTriggeringPipeline: true
        allowPartiallySucceededBuilds: true
        allowFailedBuilds: false
        buildVersionToDownload: 'latestFromBranch'
        branchName: 'refs/heads/main'
        # patterns: '**/*$(artifact_platform)_python$(py_ver)*'
        # patterns: '**/*artifacts*$(artifact_platform)_numpy$(np_ver)python$(py_ver)*'
        patterns: '**/*artifacts*$(artifact_platform)_python$(py_ver)*'
      displayName: Download Phenix package

    # download latest chem_data package
    - task: DownloadPipelineArtifact@2
      inputs:
        source: 'specific'
        project: '$(resources.pipeline.phenix_feedstock.projectID)'
        pipeline: '$(resources.pipeline.phenix_feedstock.pipelineID)'
        preferTriggeringPipeline: false
        allowPartiallySucceededBuilds: true
        allowFailedBuilds: false
        buildVersionToDownload: 'latestFromBranch'
        branchName: 'refs/heads/chem_data'
        patterns: '**/*artifacts*linux*'
      displayName: Download chem_data package

    - script: |
        mkdir $(Pipeline.Workspace)\$(platform)
        mkdir $(Pipeline.Workspace)\noarch

        cd $(Pipeline.Workspace)
        dir

        for /D %%D in (conda_artifacts*) do (
          cd %%D
          dir
          unzip -o phenix-feedstock*.zip

          cd $(Pipeline.Workspace)
          cd %%D
          dir
          cd $(platform)
          for /R %%F in (phenix*.conda) do (
            move %%F $(Pipeline.Workspace)\$(platform)\
          )

          cd $(Pipeline.Workspace)
          cd %%D
          cd build_artifacts\noarch
          for /R %%F in (chem_data*.conda) do (
            move %%F $(Pipeline.Workspace)\noarch\
          )

          cd $(Pipeline.Workspace)
          rmdir /S /Q %%D
        )

        cd $(Pipeline.Workspace)
        dir $(platform)
        dir noarch
      displayName: Extract artifact

    - script: |
        call activate construct
        cd $(Pipeline.Workspace)
        call conda index .
        dir
      displayName: Index file channel

    - bash: |
        cd constructor
        version=`python3 update_version.py --version windows`
        echo ${version}
        echo $(version)
        echo "##vso[task.setVariable variable=version]$version"
      displayName: Set and update version

    - script: |
        call activate upload
        echo $(version)
        cd $(Pipeline.Workspace)\$(platform)
        for /R $(Pipeline.Workspace)\$(platform) %%F in (phenix*.conda) do (
          echo "Uploading %%F"
          python $(Build.Repository.LocalPath)/scripts/google_drive.py ^
            --credentials $(upload_key.secureFilePath) ^
            --drive "Phenix Installers" ^
            --folder $(version) ^
            --subfolder $(platform) ^
            --file %%F
        )
      displayName: Upload conda package to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true

    - script: |
        echo on

        call activate construct
        if exist C:\Miniconda\envs\phenix\ (
          call conda remove -n phenix -y --all
        )

        cd $(Pipeline.Workspace)\$(platform)

        call conda create -n phenix -y -c conda-forge python=$(py_ver)
        if %errorlevel% neq 0 exit /b %errorlevel%

        for /R $(Pipeline.Workspace)\$(platform) %%F in (phenix*.conda) do (
          echo "Installing %%F"
          call conda install -n phenix -y -c local %%F
          if %errorlevel% neq 0 exit /b %errorlevel%
        )

        call conda install -n phenix -y --file C:\Miniconda\envs\phenix\Library\share\phenix\conda_envs\phenix_py$(pyver)_$(platform).txt2
        if %errorlevel% neq 0 exit /b %errorlevel%

        call conda install -n phenix -y -c conda-forge --override-channels --no-deps --freeze-installed menuinst
        if %errorlevel% neq 0 exit /b %errorlevel%

        for /R $(Pipeline.Workspace)\noarch %%F in (chem_data*.conda) do (
          echo "Installing %%F"
          call conda install -n phenix -y %%F
          if %errorlevel% neq 0 exit /b %errorlevel%
        )

        call conda clean -y --all
      displayName: Create installer environment
      retryCountOnTaskFailure: 3

    - script: |
        call activate construct
        call conda info --envs
        cd constructor
        constructor .
        if %errorlevel% neq 0 exit /b %errorlevel%
        dir
      displayName: Create installer

    - script: |
        call activate upload

        cd constructor
        for /R %%F in (Phenix*) do (
          echo Uploading %%F
          python $(Build.Repository.LocalPath)/scripts/google_drive.py ^
            --credentials $(upload_key.secureFilePath) ^
            --drive "Phenix Installers" ^
            --folder $(version) ^
            --subfolder $(py_ver) ^
            --file %%F
        )
      displayName: Upload installer to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true

    - task: CopyFilesOverSSH@0
      inputs:
        sshEndpoint: cci3
        sourceFolder: $(Build.Repository.LocalPath)/constructor
        contents: Phenix*.exe
        targetFolder: /net/cci-filer2/raid1/auto_build/phenix_installers/$(version)
        overwrite: false
      displayName: Upload installer to Berkeley
      condition: and(eq(variables['py_ver'], '3.9'), succeeded())
      continueOnError: true

# =============================================================================
- stage: Clean
  dependsOn: [linux_macOS, win]
  condition: succeededOrFailed()

  jobs:
  - job: Clean_my_drive

    steps:

    - task: DownloadSecureFile@1
      name: upload_key
      inputs:
        secureFile: phenix-lbl-04e6cb0d1bf7.json

    # download sources
    - checkout: self

    - script: |
        set -xe

        pwd
        ls

        cd $(Pipeline.Workspace)
        pwd
        ls
      displayName: Debug information

    - bash: sudo chown -R $USER $CONDA
      displayName: Take ownership of conda installation

    # add conda to path
    # https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/anaconda?view=azure-devops&tabs=ubuntu-16-04#add-conda-to-your-system-path
    - bash: echo "##vso[task.prependpath]$CONDA/bin"
      displayName: Add conda to PATH

    # set up Google Drive upload environment
    - script: |
        set -xe
        if [ -d $(Pipeline.Workspace)/miniforge/envs/upload ]; then
          conda remove -n upload -y --all
        fi
        conda create -n upload -y python=3.10
        source activate upload
        pip install --no-input google-api-python-client google-auth-httplib2 google-auth-oauthlib oauth2client
      displayName: Set up upload environment
      retryCountOnTaskFailure: 3

    - script: |
        set -xe

        source activate upload

        python $(Build.Repository.LocalPath)/scripts/google_drive.py \
          --credentials $(upload_key.secureFilePath) \
          --drive "Phenix Installers" \
          --cleanup
      displayName: Clean up drive
