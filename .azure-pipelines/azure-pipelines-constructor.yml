# Run constructor after phenix-feedstock finishes

# no continuous integration builds or pull requests
trigger: none
pr: none

resources:
  pipelines:
  - pipeline: phenix_feedstock
    project: 'feedstock-builds'
    source: 'phenix-feedstock'
    branch: 'main'
    trigger:
      branches:
        include:
          - main

stages:
# =============================================================================
- stage: linux_macOS

  jobs:
  - job: Construct_phenix_installer

    strategy:
      maxParallel: 6
      matrix:
        linux_py37:
          vmImage: ubuntu-latest
          artifact_platform: linux_64
          platform: linux-64
          py_ver: 3.7
          np_ver: 1.20
        linux_py38:
          vmImage: ubuntu-latest
          artifact_platform: linux_64
          platform: linux-64
          py_ver: 3.8
          np_ver: 1.20
        linux_py39:
          vmImage: ubuntu-latest
          artifact_platform: linux_64
          platform: linux-64
          py_ver: 3.9
          np_ver: 1.20
        linux_py310:
          vmImage: ubuntu-latest
          artifact_platform: linux_64
          platform: linux-64
          py_ver: 3.10
          np_ver: 1.21
        macOS_py37:
          vmImage: macOS-latest
          artifact_platform: osx_64
          platform: osx-64
          py_ver: 3.7
          np_ver: 1.20
        macOS_py38:
          vmImage: macOS-latest
          artifact_platform: osx_64
          platform: osx-64
          py_ver: 3.8
          np_ver: 1.20
        macOS_py39:
          vmImage: macOS-latest
          artifact_platform: osx_64
          platform: osx-64
          py_ver: 3.9
          np_ver: 1.20
        macOS_py310:
          vmImage: macOS-latest
          artifact_platform: osx_64
          platform: osx-64
          py_ver: 3.10
          np_ver: 1.21
        macOS_arm64_py38:
          vmImage: macOS-latest
          artifact_platform: osx_arm64
          platform: osx-arm64
          py_ver: 3.8
          np_ver: 1.20
        macOS_arm64_py39:
          vmImage: macOS-latest
          artifact_platform: osx_arm64
          platform: osx-arm64
          py_ver: 3.9
          np_ver: 1.20
        macOS_arm64_py310:
          vmImage: macOS-latest
          artifact_platform: osx_arm64
          platform: osx-arm64
          py_ver: 3.10
          np_ver: 1.21

    pool:
      vmImage: $(vmImage)
    timeoutInMinutes: 360

    # variable for version
    variables:
      version: 1234

    steps:

    - task: InstallSSHKey@0
      inputs:
        knownHostsEntry: boa.lbl.gov ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAnPOtqyYASs6hc3fsmUQn92ovSozJsMsJyrMWjppUERX1tD4Fh0D7YaNhLvYpKi5mYVREo+tsKoOatCcqKGHCONWpzx7JHXUzfIBsy6nCeygRyyW4yuyoCuYFvOYLkaM4PrN/7XaZEnp1ux6/ZcbRxBDNK4f42svJUV39OX33tRuQWpP+O85paJr1ePHVz6U2n14a+3fRN3DBMti1dJuKOThU4djYEBQimx54pnW71eYORN2oUz+N/4RHAcomtxZpcUMl3Qadw8hD4s1XM6fzJ0Que7KefnnrPOgAEtZxKl9j09aaE70Oh+ie5Y6ckwddJ/4qZB5m2tBaEi3xuy0TSQ==
        sshPublicKey: ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA7XgVgdU9GmZuo5yVyW/htrAuxe7ypuq7IowWwfUC0WZw9SPzQ8kOGj63plF3ytx/qpgvUlS1AiywO20rZ83gHmRdAiuvt9laH09KlWEUhIhAQTzesqBG5aUT0MKo01yxijoRl5HC8w/MdOanc0h01e6IxnZvgG0N30RB1i4xVPCtR/VBmXSp4R0T+Q/gJjfQssuBxHVMrrute4V3uUHek58FL2QgUB0+zq6ipETjuCJxTSyYVAFtCYDPYs+0lAYYkWrXALCr9kX9s22jYtkyv5kNw6mEW8nhtA7GbTdJLv4M6/WYtcvQV8TDcNCfltOfl81U3gcZ9zhQDKGVoNaJEw== buildbot@cci.lbl.gov
        sshKeySecureFile: id_rsa
      displayName: Download SSH key

    - task: DownloadSecureFile@1
      name: upload_key
      inputs:
        secureFile: phenix-lbl-04e6cb0d1bf7.json
      displayName: Download Google Drive credentials

    - task: DownloadSecureFile@1
      name: ssh_config
      inputs:
        secureFile: ssh.config
      displayName: Download SSH config

    # download sources
    - checkout: self

    # clean up linux image
    - script: |
        sudo $(Build.Repository.LocalPath)/scripts/clean_linux.sh
      displayName: Clean up linux image
      condition: eq(variables['platform'], 'linux-64')

    - script: |
        set -xe

        pwd
        ls

        cd $(Pipeline.Workspace)
        pwd
        ls
      displayName: Debug information

    - bash: sudo chown -R $USER $CONDA
      displayName: Take ownership of conda installation

    # add conda to path
    # https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/anaconda?view=azure-devops&tabs=ubuntu-16-04#add-conda-to-your-system-path
    - bash: echo "##vso[task.prependpath]$CONDA/bin"
      displayName: Add conda to PATH

    # install mamba
    - script: |
        set -xe
        conda install -n base -y conda=24
        conda update -n base -y --all
        conda install -n base -y conda-build
        conda info
      displayName: Install conda-build
      retryCountOnTaskFailure: 3

    # set up constructor environment
    - script: |
        set -xe
        conda remove -n construct -y --all
        # conda create -n construct -y -c conda-forge ctools/label/dev::constructor
        conda create -n construct -y -c conda-forge constructor=3.4.4 jinja2
      displayName: Set up constructor environment
      retryCountOnTaskFailure: 3

    # set up Google Drive upload environment
    - script: |
        set -xe
        conda remove -n upload -y --all
        conda create -n upload -y python=3.10
        source activate upload
        pip install --no-input google-api-python-client google-auth-httplib2 google-auth-oauthlib oauth2client
      displayName: Set up upload environment
      retryCountOnTaskFailure: 3

    - script: |
        set -xe

        rm -fr $(Pipeline.Workspace)/conda*

        conda clean -y --all

        conda config --set solver classic
        source activate construct
        constructor --clean
        conda config --set solver libmamba

        df -h

      displayName: Clean up

    # download latest phenix conda package
    - task: DownloadPipelineArtifact@2
      inputs:
        source: 'specific'
        project: '$(resources.pipeline.phenix_feedstock.projectID)'
        pipeline: '$(resources.pipeline.phenix_feedstock.pipelineID)'
        preferTriggeringPipeline: true
        allowPartiallySucceededBuilds: true
        allowFailedBuilds: false
        buildVersionToDownload: 'latestFromBranch'
        branchName: 'refs/heads/main'
        # patterns: '**/*$(artifact_platform)_python$(py_ver)*'
        patterns: '**/*artifacts*$(artifact_platform)_numpy$(np_ver)python$(py_ver)*'
      displayName: Download Phenix package

    # download latest chem_data package
    - task: DownloadPipelineArtifact@2
      inputs:
        source: 'specific'
        project: '$(resources.pipeline.phenix_feedstock.projectID)'
        pipeline: '$(resources.pipeline.phenix_feedstock.pipelineID)'
        preferTriggeringPipeline: true
        allowPartiallySucceededBuilds: true
        allowFailedBuilds: false
        buildVersionToDownload: 'latestFromBranch'
        branchName: 'refs/heads/chem_data'
        patterns: '**/*artifacts*linux*'
      displayName: Download chem_data package

    - script: |
        set -xe

        mkdir $(Pipeline.Workspace)/$(platform)
        mkdir $(Pipeline.Workspace)/noarch

        cd $(Pipeline.Workspace)
        ls

        for d in conda_artifacts*/; do
          cd $(Pipeline.Workspace)/${d}
          unzip phenix-feedstock*.zip

          if [ -d build_artifacts/$(platform) ]; then
            cd build_artifacts/$(platform)
          elif [ -d $(platform) ]; then
            cd $(platform)
          fi
          for f in `/bin/ls phenix*.conda 2> /dev/null`; do
            mv ${f} $(Pipeline.Workspace)/$(platform)/
          done

          if [ -d $(Pipeline.Workspace)/${d}/build_artifacts/noarch ]; then
            cd $(Pipeline.Workspace)/${d}/build_artifacts/noarch
            for f in `/bin/ls chem_data*.conda 2> /dev/null`; do
              mv ${f} $(Pipeline.Workspace)/noarch/
            done
          fi
        done

        rm -fr $(Pipeline.Workspace)/conda_artifacts*

        ls $(Pipeline.Workspace)/$(platform)/
        ls $(Pipeline.Workspace)/noarch/
      displayName: Extract artifact

    - script: |
        set -xe
        cd $(Pipeline.Workspace)
        conda index .
        ls
      displayName: Index file channel

    - script: |
        set -xe
        cd constructor
        version=`python3 update_version.py --version $(Pipeline.Workspace)/$(platform)/phenix*`
        echo "##vso[task.setVariable variable=version]$version"
        echo $(version)
      displayName: Set and update version

    - script: |
        set -xe

        source activate upload

        cd $(Pipeline.Workspace)/$(platform)
        for f in `/bin/ls $(Pipeline.Workspace)/$(platform)/*.conda`; do
          echo Uploading ${f}
          python $(Build.Repository.LocalPath)/scripts/google_drive.py \
            --credentials $(upload_key.secureFilePath) \
            --drive "Phenix Installers" \
            --folder "$(version)" \
            --subfolder "$(platform)" \
            --file ${f}
          sleep 60
        done
      displayName: Upload platform conda package to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true

    - script: |
        set -xe

        source activate upload

        cd $(Pipeline.Workspace)/noarch
        for f in `/bin/ls $(Pipeline.Workspace)/noarch/*.conda`; do
          echo Uploading ${f}
          python $(Build.Repository.LocalPath)/scripts/google_drive.py \
            --credentials $(upload_key.secureFilePath) \
            --drive "Phenix Installers" \
            --folder "$(version)" \
            --subfolder "noarch" \
            --file ${f}
          sleep 60
        done
      displayName: Upload noarch conda package to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true
      condition: and(eq(variables['py_ver'], '3.7'), eq(variables['platform'], 'linux-64'))

    - script: |
        set -xe

        conda remove -n phenix -y --all

        conda create -n phenix -y
        source activate phenix

        cd $(Pipeline.Workspace)/$(platform)
        conda install -y phenix*.conda

        cd ${CONDA_PREFIX}/share/phenix/conda_envs

        pyver=`echo $(py_ver) | sed 's/\.//'`

        conda install -y --file phenix_py${pyver}_$(platform).txt
        if [[ "$(platform)" != *"arm64" ]]; then
          conda install -y -c cctbx202211 --no-deps --freeze-installed gemmi nxmx
        fi

        cd $(Pipeline.Workspace)/noarch
        conda install -y chem_data*.conda

        conda clean -y --all

        conda config --set solver classic
      displayName: Create installer environment
      retryCountOnTaskFailure: 3

    - script: |
        set -xe

        source activate phenix

        cp ${CONDA_PREFIX}/share/phenix/CHANGES ./constructor/gui/readme_macos.txt
      displayName: Update Changelog

    - script: |
        set -xe

        df -h
      displayName: Check disk space

    - script: |
        set -xe

        # cross-platform constructor
        if [[ "$(platform)" == *"arm64" ]]; then
          TEMP_DIR=$(mktemp -d)
          CONDA_SUBDIR=$(platform) conda create -p ${TEMP_DIR} -y -c defaults conda-standalone
          CONDA_STANDALONE=${TEMP_DIR}/standalone_conda/conda.exe
        fi

        conda config --set solver classic
        source activate construct
        cd constructor

        if [[ "$(platform)" == *"arm64" ]]; then
          constructor . --conda-exe ${CONDA_STANDALONE} --platform osx-arm64
        else
          constructor .
        fi

        ls
        df -h
      displayName: Create installer
      retryCountOnTaskFailure: 3

    - script: |
        set -xe

        source activate upload

        cd ./constructor
        for f in `/bin/ls Phenix*`; do
          echo Uploading ${f}
          python $(Build.Repository.LocalPath)/scripts/google_drive.py \
            --credentials $(upload_key.secureFilePath) \
            --drive "Phenix Installers" \
            --folder "$(version)" \
            --subfolder "$(py_ver)" \
            --file ${f}
          sleep 60
        done

      displayName: Upload installer to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true

    - task: CopyFilesOverSSH@0
      inputs:
        sshEndpoint: anaconda
        sourceFolder: $(Build.Repository.LocalPath)/constructor
        contents: Phenix*
        targetFolder: /net/cci-filer2/raid1/auto_build/phenix_installers/$(version)
        overwrite: false
      displayName: Upload installer
      condition: or(eq(variables['py_ver'], '3.7'),
                    and(eq(variables['py_ver'], '3.9'), eq(variables['platform'], 'osx-arm64')))
      continueOnError: true

# =============================================================================
- stage: win
  dependsOn: []

  jobs:
  - job: Construct_phenix_win_installer

    strategy:
      matrix:
        win_py37:
          vmImage: windows-latest
          artifact_platform: win_64
          platform: win-64
          py_ver: 3.7
          pyver: 37
          np_ver: 1.20
        win_py38:
          vmImage: windows-latest
          artifact_platform: win_64
          platform: win-64
          py_ver: 3.8
          pyver: 38
          np_ver: 1.20
        win_py39:
          vmImage: windows-latest
          artifact_platform: win_64
          platform: win-64
          py_ver: 3.9
          pyver: 39
          np_ver: 1.20
        win_py310:
          vmImage: windows-latest
          artifact_platform: win_64
          platform: win-64
          py_ver: 3.10
          pyver: 310
          np_ver: 1.21

    pool:
      vmImage: $(vmImage)
    timeoutInMinutes: 360

    # variable for version
    variables:
      version: 1234

    steps:

    - task: InstallSSHKey@0
      inputs:
        knownHostsEntry: boa.lbl.gov ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEAnPOtqyYASs6hc3fsmUQn92ovSozJsMsJyrMWjppUERX1tD4Fh0D7YaNhLvYpKi5mYVREo+tsKoOatCcqKGHCONWpzx7JHXUzfIBsy6nCeygRyyW4yuyoCuYFvOYLkaM4PrN/7XaZEnp1ux6/ZcbRxBDNK4f42svJUV39OX33tRuQWpP+O85paJr1ePHVz6U2n14a+3fRN3DBMti1dJuKOThU4djYEBQimx54pnW71eYORN2oUz+N/4RHAcomtxZpcUMl3Qadw8hD4s1XM6fzJ0Que7KefnnrPOgAEtZxKl9j09aaE70Oh+ie5Y6ckwddJ/4qZB5m2tBaEi3xuy0TSQ==
        sshPublicKey: ssh-rsa AAAAB3NzaC1yc2EAAAABIwAAAQEA7XgVgdU9GmZuo5yVyW/htrAuxe7ypuq7IowWwfUC0WZw9SPzQ8kOGj63plF3ytx/qpgvUlS1AiywO20rZ83gHmRdAiuvt9laH09KlWEUhIhAQTzesqBG5aUT0MKo01yxijoRl5HC8w/MdOanc0h01e6IxnZvgG0N30RB1i4xVPCtR/VBmXSp4R0T+Q/gJjfQssuBxHVMrrute4V3uUHek58FL2QgUB0+zq6ipETjuCJxTSyYVAFtCYDPYs+0lAYYkWrXALCr9kX9s22jYtkyv5kNw6mEW8nhtA7GbTdJLv4M6/WYtcvQV8TDcNCfltOfl81U3gcZ9zhQDKGVoNaJEw== buildbot@cci.lbl.gov
        sshKeySecureFile: id_rsa
      displayName: Download SSH key

    - task: DownloadSecureFile@1
      name: upload_key
      inputs:
        secureFile: phenix-lbl-04e6cb0d1bf7.json
      displayName: Download Google Drive credentials

    - task: DownloadSecureFile@1
      name: ssh_config
      inputs:
        secureFile: ssh.config
      displayName: Download SSH config

    - task: DownloadSecureFile@1
      name: nsis_zip
      inputs:
        secureFile: nsis-binary-7336-1.zip
      displayName: Download nsisbi

    # download sources
    - checkout: self

    # add conda to path
    # https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/anaconda?view=azure-devops&tabs=windows#add-conda-to-your-system-path
    - powershell: Write-Host "##vso[task.prependpath]$env:CONDA\Scripts"
      displayName: Add conda to PATH

    # install mamba
    - script: |
        conda install -n base -y conda=24
        conda update -n base -y --all
        conda install -n base -y conda-build
        conda info
      displayName: Install conda-build
      retryCountOnTaskFailure: 3

    # set up constructor environment
    - script: |
        conda remove -n construct -y --all
        conda create -n construct -y -c conda-forge constructor=3.4.4 jinja2
      displayName: Set up constructor environment
      retryCountOnTaskFailure: 3

    # replace nsis with nsisbi
    - script: |
        unzip $(nsis_zip.secureFilePath)
        xcopy /S /Y /F nsis-binary-7336-1\* C:\Miniconda\envs\construct\NSIS
        dir nsis-binary-7336-1
        dir C:\Miniconda\envs\construct\NSIS
      displayName: Replace NSIS in constructor environment

    # set up Google Drive upload environment
    - script: |
        conda remove -n upload -y --all
        conda create -n upload -y python=3.10
        call activate upload
        pip install --no-input google-api-python-client google-auth-httplib2 google-auth-oauthlib oauth2client
      displayName: Set up upload environment
      retryCountOnTaskFailure: 3

    # download latest phenix conda package
    - task: DownloadPipelineArtifact@2
      inputs:
        source: 'specific'
        project: '$(resources.pipeline.phenix_feedstock.projectID)'
        pipeline: '$(resources.pipeline.phenix_feedstock.pipelineID)'
        preferTriggeringPipeline: true
        allowPartiallySucceededBuilds: true
        allowFailedBuilds: false
        buildVersionToDownload: 'latestFromBranch'
        branchName: 'refs/heads/main'
        # patterns: '**/*$(artifact_platform)_python$(py_ver)*'
        patterns: '**/*artifacts*$(artifact_platform)_numpy$(np_ver)python$(py_ver)*'
      displayName: Download Phenix package

    # download latest chem_data package
    - task: DownloadPipelineArtifact@2
      inputs:
        source: 'specific'
        project: '$(resources.pipeline.phenix_feedstock.projectID)'
        pipeline: '$(resources.pipeline.phenix_feedstock.pipelineID)'
        preferTriggeringPipeline: true
        allowPartiallySucceededBuilds: true
        allowFailedBuilds: false
        buildVersionToDownload: 'latestFromBranch'
        branchName: 'refs/heads/chem_data'
        patterns: '**/*artifacts*linux*'
      displayName: Download chem_data package

    - script: |
        mkdir $(Pipeline.Workspace)\$(platform)
        mkdir $(Pipeline.Workspace)\noarch

        cd $(Pipeline.Workspace)
        dir

        for /D %%D in (conda_artifacts*) do (
          cd %%D
          dir
          unzip -o phenix-feedstock*.zip

          cd $(Pipeline.Workspace)
          cd %%D
          dir
          cd $(platform)
          for /R %%F in (phenix*.conda) do (
            move %%F $(Pipeline.Workspace)\$(platform)\
          )

          cd $(Pipeline.Workspace)
          cd %%D
          cd build_artifacts\noarch
          for /R %%F in (chem_data*.conda) do (
            move %%F $(Pipeline.Workspace)\noarch\
          )

          cd $(Pipeline.Workspace)
          rmdir /S /Q %%D
        )

        cd $(Pipeline.Workspace)
        dir $(platform)
        dir noarch
      displayName: Extract artifact

    - script: |
        cd $(Pipeline.Workspace)
        conda index .
        dir
      displayName: Index file channel

    - bash: |
        cd constructor
        version=`python3 update_version.py --version windows`
        echo ${version}
        echo $(version)
        echo "##vso[task.setVariable variable=version]$version"
      displayName: Set and update version

    - script: |
        call activate upload
        echo $(version)
        cd $(Pipeline.Workspace)\$(platform)
        for /R $(Pipeline.Workspace)\$(platform) %%F in (phenix*.conda, phenix*tar.bz2) do (
          echo "Uploading %%F"
          python $(Build.Repository.LocalPath)/scripts/google_drive.py ^
            --credentials $(upload_key.secureFilePath) ^
            --drive "Phenix Installers" ^
            --folder $(version) ^
            --subfolder $(platform) ^
            --file %%F
        )
      displayName: Upload conda package to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true

    - script: |
        conda remove -n phenix -y --all

        cd $(Pipeline.Workspace)\$(platform)
        conda create -n phenix -y
        for /R $(Pipeline.Workspace)\$(platform) %%F in (phenix*.conda, phenix*tar.bz2) do (
          conda install -n phenix -y %%F
        )
        conda install -n phenix -y --file C:\Miniconda\envs\phenix\Library\share\phenix\conda_envs\phenix_py$(pyver)_$(platform).txt
        conda install -n phenix -y -c cctbx202211 --override-channels --no-deps --freeze-installed gemmi nxmx
        conda install -n phenix -y -c conda-forge --override-channels --no-deps --freeze-installed menuinst

        for /R $(Pipeline.Workspace)\noarch %%F in (chem_data*.conda) do (
          conda install -n phenix -y %%F
        )

        conda clean -y --all
      displayName: Create installer environment
      retryCountOnTaskFailure: 3

    - script: |
        conda config --set solver classic
        call activate construct
        cd constructor
        constructor .
        if %errorlevel% neq 0 exit /b %errorlevel%
        dir
      displayName: Create installer

    - script: |
        call activate upload

        cd constructor
        for /R %%F in (Phenix*) do (
          echo Uploading %%F
          python $(Build.Repository.LocalPath)/scripts/google_drive.py ^
            --credentials $(upload_key.secureFilePath) ^
            --drive "Phenix Installers" ^
            --folder $(version) ^
            --subfolder $(py_ver) ^
            --file %%F
        )
      displayName: Upload installer to Google Drive
      retryCountOnTaskFailure: 3
      continueOnError: true

    - task: CopyFilesOverSSH@0
      inputs:
        sshEndpoint: anaconda
        sourceFolder: $(Build.Repository.LocalPath)/constructor
        contents: Phenix*.exe
        targetFolder: /net/cci-filer2/raid1/auto_build/phenix_installers/$(version)
        overwrite: false
      displayName: Upload installer
      condition: and(eq(variables['py_ver'], '3.7'), succeeded())
      continueOnError: true

# =============================================================================
- stage: Clean
  dependsOn: [linux_macOS, win]
  condition: succeededOrFailed()

  jobs:
  - job: Clean_my_drive

    steps:

    - task: DownloadSecureFile@1
      name: upload_key
      inputs:
        secureFile: phenix-lbl-04e6cb0d1bf7.json

    # download sources
    - checkout: self

    - script: |
        set -xe

        pwd
        ls

        cd $(Pipeline.Workspace)
        pwd
        ls
      displayName: Debug information

    - bash: sudo chown -R $USER $CONDA
      displayName: Take ownership of conda installation

    # add conda to path
    # https://docs.microsoft.com/en-us/azure/devops/pipelines/ecosystems/anaconda?view=azure-devops&tabs=ubuntu-16-04#add-conda-to-your-system-path
    - bash: echo "##vso[task.prependpath]$CONDA/bin"
      displayName: Add conda to PATH

    # set up Google Drive upload environment
    - script: |
        set -xe
        conda remove -n upload -y --all
        conda create -n upload -y python=3.10
        source activate upload
        pip install --no-input google-api-python-client google-auth-httplib2 google-auth-oauthlib oauth2client
      displayName: Set up upload environment
      retryCountOnTaskFailure: 3

    - script: |
        set -xe

        source activate upload

        python $(Build.Repository.LocalPath)/scripts/google_drive.py \
          --credentials $(upload_key.secureFilePath) \
          --drive "Phenix Installers" \
          --cleanup
      displayName: Clean up drive
